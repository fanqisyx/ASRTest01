唤醒词识别软件开发文档
1. 项目概览
本项目将开发一个轻量级的**唤醒词识别（Keyword Spotting, KWS）**软件系统。该系统利用 TensorFlow Lite Micro 框架，旨在实现在资源受限的微控制器或嵌入式设备上，实时、低功耗地检测特定唤醒词的功能。

2. 软件需求规格说明 (Software Requirements Specification - SRS)
2.1 功能性需求 (Functional Requirements)
F.1 实时唤醒词检测： 软件应能够从麦克风实时捕获音频数据流，并持续分析以检测预设的唤醒词。

F.2 特定唤醒词支持： 软件应能够准确识别至少一个预设的唤醒词（例如：“嗨，小助手”或“打开设备”）。初期可基于Google Speech Commands数据集中的现有单词进行实验，后续可扩展为自定义唤醒词。

F.3 低延迟响应： 从唤醒词被完整说出到软件发出识别信号的延迟应小于 200 毫秒，以确保用户体验的流畅性。

F.4 识别结果输出： 一旦检测到唤醒词，软件应通过可编程的接口（如串口打印信息、点亮LED指示灯、或GPIO电平变化）清晰地发出信号。

F.5 模型加载与执行： 软件应能够加载预训练并转换好的 TensorFlow Lite Micro 模型，并在嵌入式设备上高效地执行推理。

F.6 音频数据预处理： 软件应包含将原始麦克风数据转换为模型所需特征（如梅尔频谱图）的模块。

2.2 非功能性需求 (Non-Functional Requirements)
NF.1 性能要求：

准确率 (Accuracy)： 唤醒词的正确识别率目标为大于 90%（在测试集上）。

误唤醒率 (False Alarm Rate - FAR)： 每小时误唤醒次数应少于 2 次（在无唤醒词的背景音频测试中）。

漏唤醒率 (False Rejection Rate - FRR)： 在唤醒词被正确发出时，未被识别的比例应小于 5%。

NF.2 资源占用：

内存 (RAM) 占用： 整个 KWS 软件（包括模型、运行库和数据缓冲区）的 RAM 占用应小于目标设备总 RAM 的 70%。

闪存 (Flash) 占用： 编译后的固件大小（包括代码和模型文件）应小于目标设备总 Flash 的 80%。

NF.3 实时性： 软件应能够实时处理音频流，避免出现数据堆积或处理延迟过大导致丢帧。

NF.4 鲁棒性：

环境噪声： 在日常室内环境（如办公室、客厅）的背景噪声下，仍能保持较高的识别准确率。

说话人独立性： 能够识别不同说话人发出的唤醒词（即使模型未针对特定说话人进行训练）。

NF.5 移植性： 软件代码结构应清晰，便于未来移植到其他类似的微控制器平台。

NF.6 可配置性： 核心参数（如阈值）应可以通过代码修改或编译选项进行调整，无需重新训练模型。

NF.7 功耗： 在空闲监听模式下，设备的平均功耗应尽可能低，以延长电池寿命。

3. 技术路径手册 (Technical Path Handbook)
本项目的技术路径将分为以下核心阶段：

3.1 阶段一：数据准备与特征工程 (Python)
数据集选择/创建：

推荐： 优先使用 Google Speech Commands Dataset v0.02 进行初期实验，该数据集已包含多种唤醒词和背景噪声。

自定义唤醒词： 若需，自行录制自定义唤醒词的语音数据。确保包括：

正样本： 目标唤醒词在不同人、不同语速、不同音量下的录音。

负样本： 其他日常对话、环境噪声、无语音片段等，以训练模型区分非唤醒词。

音频预处理：

统一采样率： 将所有音频文件重采样至 16kHz（标准语音识别采样率）。

规范化： 统一音频通道（单声道）和位深（16-bit PCM）。

特征提取：

方法： 计算音频的梅尔频谱图（Mel-spectrogram）。

参数： 帧长（例如 25ms）、帧移（例如 10ms）、梅尔滤波器数量（例如 40 个）。

库： 使用 Python 的 librosa 库进行特征提取，确保特征计算逻辑与后续嵌入式端实现一致。

数据增强 (Data Augmentation)：

目的： 增加训练数据的多样性，提高模型的鲁棒性。

技术： 随机加入背景噪声（从背景噪声集中选取）、调整音量、随机裁剪（截取固定长度的音频片段）、时间拉伸/压缩等。

数据集划分： 将准备好的特征数据划分为训练集、验证集和测试集（典型比例 80%:10%:10%）。

3.2 阶段二：模型训练与优化 (Python/TensorFlow)
模型架构设计：

基础： 基于 2D 卷积神经网络 (CNN)。

推荐结构：

输入层： 接收梅尔频谱图（例如，假设每段音频固定为1秒，16kHz采样率，25ms帧长/10ms帧移，40个梅尔滤波器，则输入尺寸为 100×40）。

卷积层： 多个 2D 卷积层，可使用 深度可分离卷积 (Depthwise Separable Convolution) 降低参数量和计算量。

激活函数： ReLU。

池化层： 平均池化 (Average Pooling) 或最大池化 (Max Pooling)。

批归一化 (Batch Normalization)： 提高训练稳定性。

全连接层： 用于最终分类。

输出层： Softmax 激活函数，输出唤醒词和非唤醒词的概率。

参考： Google TensorFlow Lite Micro Speech 示例中的模型结构是一个很好的起点。

模型训练：

框架： 使用 TensorFlow 2.x。

损失函数： 分类交叉熵 (Categorical Cross-entropy)。

优化器： Adam 优化器。

批次大小 (Batch Size)： 根据 GPU 内存适当调整。

训练轮次 (Epochs)： 根据验证集性能决定。

学习率调度： 适当的学习率衰减策略。

模型评估：

在验证集上监控训练过程，防止过拟合。

在独立的测试集上全面评估模型性能，包括准确率、FAR 和 FRR。

3.3 阶段三：模型转换与量化 (Python/TensorFlow Lite)
TensorFlow Lite 模型转换：

使用 tf.lite.TFLiteConverter 将训练好的 TensorFlow 模型转换为 .tflite 格式。

重要： 确保模型的输入和输出节点名称与后续在嵌入式端匹配。

模型量化：

类型： 优先采用全整数量化 (Full Integer Quantization)。这将模型的所有权重和激活值转换为 8 位整数，极大减小模型大小并加速推理。

校准数据集： 提供一个小型的代表性数据集（通常是验证集的一个子集）进行量化校准，以确定每个张量的动态范围。

输出格式： 量化后的模型应保存为 .tflite 文件。

3.4 阶段四：嵌入式部署 (C/C++/TensorFlow Lite Micro)
目标硬件平台选择：

推荐： ESP32 (如 ESP32-LyraT, ESP32-S3-Korvo等具有音频输入的开发板)、STM32系列微控制器 (如 STM32F4/F7/H7 开发板)、Arduino Nano 33 BLE Sense 等。这些平台具备足够的处理能力、内存和音频接口。

开发环境搭建：

IDE/工具链： 根据所选目标平台，安装相应的开发工具链（如 ESP-IDF for ESP32, STM32CubeIDE for STM32, Arduino IDE for Arduino）。

TensorFlow Lite Micro 库集成： 从 TensorFlow GitHub 仓库克隆代码，并根据目标平台编译和集成 TensorFlow Lite Micro 库。

音频输入模块开发：

硬件接口： 编写驱动程序以配置和读取麦克风（如 I2S 接口的 MEMS 麦克风或 ADC 接口的模拟麦克风）。

数据缓冲区： 实现循环缓冲区或双缓冲区机制，持续接收和存储麦克风采集的音频样本。

采样率匹配： 确保麦克风的采样率与模型训练时的采样率（16kHz）一致。

实时特征提取模块：

在 C/C++ 中实现与 Python 阶段完全一致的梅尔频谱图计算逻辑。

优化： 利用目标 MCU 的 DSP 指令集（如 ARM Cortex-M 系列的 CMSIS-DSP 库）来加速 FFT、矩阵乘法等计算，以满足实时性要求。

帧处理： 实现滑动窗口机制，按帧提取特征。

TensorFlow Lite Micro 推理引擎集成：

将量化后的 .tflite 模型文件转换为 C/C++ 数组，嵌入到固件中。

使用 TensorFlow Lite Micro API（tflite::MicroMutableOpResolver、tflite::MicroInterpreter 等）加载模型、分配张量内存。

将实时计算出的梅尔频谱图特征作为输入，调用 interpreter->Invoke() 执行模型推理。

获取模型输出的唤醒词概率。

结果判决与反馈：

根据模型输出的唤醒词概率，设置一个阈值进行判决。

实现滑动平均或状态机等机制，避免单帧误判导致频繁误唤醒。

通过串口、LED 或 GPIO 接口输出识别结果。

4. 项目要求与注意事项
文档化： 详细记录每个阶段的设计、实现细节、遇到的问题及解决方案。代码应有充分的注释。

版本控制： 使用 Git 进行版本控制，定期提交代码。

测试：

单元测试： 对特征提取、模型推理等关键模块进行单元测试。

集成测试： 部署到目标硬件后，在真实环境下进行充分的测试，验证唤醒词检测的准确率、FAR 和 FRR。

功耗测试： 如果可能，测量设备在唤醒词监听模式下的实际功耗。

资源管理： 密切关注嵌入式设备的 RAM 和 Flash 占用情况，确保在设计之初就考虑资源的限制。

代码风格： 遵循统一的 C/C++ 编码规范（如 Google C++ Style Guide 或 MISRA C/C++）。

调试： 熟练使用调试工具（如 GDB、J-Link）进行嵌入式系统的调试。